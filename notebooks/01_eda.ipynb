{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# OANDA REST-V20 API Data Fetcher\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Download historical candle data for a specified instrument, timespan and frequency, using the OANDA REST-V20 API.\n",
    "2. Build features from tick data (saved as Parquet, similarly as in point 1).\n",
    "3. Split the data into three time intervals: training, evaluation and test data.\n",
    "\n",
    "Optionally, list all available instruments from OANDA REST-V20 API\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before running this notebook:\n",
    "1. Copy `.env.example` to `.env`\n",
    "2. Fill in your OANDA API token and account ID in the `.env` file\n",
    "3. Install requirements: `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "477f919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de61e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../risk_estimator/config.py\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/fetch_data.py\n",
    "    \n",
    "# Careful! Takes 3h to fetch!\n",
    "\n",
    "# fetch_interval_complete(config['instrument'],\n",
    "#                         config['start_date'],\n",
    "#                         config['end_date'],\n",
    "#                         granularity=config['timeframe'],\n",
    "#                         price_types=('M','B','A'),\n",
    "#                         chunk_hours=6,\n",
    "#                         save_path=config['raw_data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a823654",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/build_features.py\n",
    "\n",
    "# Careful! Building features for 44M rows takes ~30min\n",
    "\n",
    "# src  = config['raw_data_path']\n",
    "# dest = config['feature_data_path']\n",
    "# col0 = config['vol_source_col_name']\n",
    "# col1 = config['vol_target_col_name']\n",
    "# freq = config['vol_shift_freq']\n",
    "# build_features(src, dest, col0, col1, shift_freq=freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e154ff44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 1014511 rows to ../data/split_2012_2014_2015/train.parquet (row_group 18)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/train.parquet (row_group 19)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/train.parquet (row_group 20)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/train.parquet (row_group 21)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/train.parquet (row_group 22)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/train.parquet (row_group 23)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/train.parquet (row_group 24)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/train.parquet (row_group 25)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/train.parquet (row_group 26)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/train.parquet (row_group 27)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/train.parquet (row_group 28)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/train.parquet (row_group 29)\n",
      "Appended 82833 rows to ../data/split_2012_2014_2015/train.parquet (row_group 30)\n",
      "Appended 965743 rows to ../data/split_2012_2014_2015/val.parquet (row_group 30)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/val.parquet (row_group 31)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/val.parquet (row_group 32)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/val.parquet (row_group 33)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/val.parquet (row_group 34)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/val.parquet (row_group 35)\n",
      "Appended 98577 rows to ../data/split_2012_2014_2015/val.parquet (row_group 36)\n",
      "Appended 949999 rows to ../data/split_2012_2014_2015/test.parquet (row_group 36)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/test.parquet (row_group 37)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/test.parquet (row_group 38)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/test.parquet (row_group 39)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/test.parquet (row_group 40)\n",
      "Appended 1048576 rows to ../data/split_2012_2014_2015/test.parquet (row_group 41)\n",
      "Appended 96982 rows to ../data/split_2012_2014_2015/test.parquet (row_group 42)\n",
      "Splitting complete. Output files: ['../data/split_2012_2014_2015/train.parquet', '../data/split_2012_2014_2015/val.parquet', '../data/split_2012_2014_2015/test.parquet']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%run ../scripts/split_dataset.py\n",
    "src = config['feature_data_path']\n",
    "dest = config['split_dir']\n",
    "train_start       = config['train_start']\n",
    "train_cutoff      = config['train_cutoff']\n",
    "val_cutoff        = config['val_cutoff']\n",
    "split_processed_parquet(src, dest, train_start, train_cutoff, val_cutoff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a96bc37",
   "metadata": {},
   "source": [
    "# Auxiliary experiments (kept to explain pitfalls) below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Function: List All Available Instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "%run ../scripts/fetch_data.py\n",
    "\n",
    "def list_instruments():\n",
    "    \"\"\"\n",
    "    List all instruments available in the OANDA account.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing instrument details\n",
    "    \"\"\"\n",
    "    url = f\"{API_URL}/v3/accounts/{ACCOUNT_ID}/instruments\"\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_TOKEN}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        instruments = data.get('instruments', [])\n",
    "        \n",
    "        # Create a DataFrame with relevant information\n",
    "        instruments_data = []\n",
    "        for inst in instruments:\n",
    "            instruments_data.append({\n",
    "                'name': inst.get('name'),\n",
    "                'type': inst.get('type'),\n",
    "                'displayName': inst.get('displayName'),\n",
    "                'pipLocation': inst.get('pipLocation'),\n",
    "                'displayPrecision': inst.get('displayPrecision'),\n",
    "                'tradeUnitsPrecision': inst.get('tradeUnitsPrecision'),\n",
    "                'minimumTradeSize': inst.get('minimumTradeSize'),\n",
    "                'maximumTrailingStopDistance': inst.get('maximumTrailingStopDistance'),\n",
    "                'minimumTrailingStopDistance': inst.get('minimumTrailingStopDistance')\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(instruments_data)\n",
    "        print(f\"Found {len(df)} instruments\")\n",
    "        return df\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching instruments: {e}\")\n",
    "        if hasattr(e.response, 'text'):\n",
    "            print(f\"Response: {e.response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Test: List All Instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 68 instruments\n",
      "\n",
      "First 10 instruments:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "displayName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pipLocation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "displayPrecision",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tradeUnitsPrecision",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "minimumTradeSize",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "maximumTrailingStopDistance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "minimumTrailingStopDistance",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e90e88d7-92f8-4650-aa46-6c60b44858a3",
       "rows": [
        [
         "0",
         "TRY_JPY",
         "CURRENCY",
         "TRY/JPY",
         "-2",
         "3",
         "0",
         "1",
         "100.000",
         "0.050"
        ],
        [
         "1",
         "AUD_JPY",
         "CURRENCY",
         "AUD/JPY",
         "-2",
         "3",
         "0",
         "1",
         "100.000",
         "0.050"
        ],
        [
         "2",
         "USD_CNH",
         "CURRENCY",
         "USD/CNH",
         "-4",
         "5",
         "0",
         "1",
         "1.00000",
         "0.00050"
        ],
        [
         "3",
         "NZD_JPY",
         "CURRENCY",
         "NZD/JPY",
         "-2",
         "3",
         "0",
         "1",
         "100.000",
         "0.050"
        ],
        [
         "4",
         "EUR_GBP",
         "CURRENCY",
         "EUR/GBP",
         "-4",
         "5",
         "0",
         "1",
         "1.00000",
         "0.00050"
        ],
        [
         "5",
         "CHF_HKD",
         "CURRENCY",
         "CHF/HKD",
         "-4",
         "5",
         "0",
         "1",
         "1.00000",
         "0.00050"
        ],
        [
         "6",
         "USD_CZK",
         "CURRENCY",
         "USD/CZK",
         "-4",
         "5",
         "0",
         "1",
         "1.00000",
         "0.00050"
        ],
        [
         "7",
         "NZD_HKD",
         "CURRENCY",
         "NZD/HKD",
         "-4",
         "5",
         "0",
         "1",
         "1.00000",
         "0.00050"
        ],
        [
         "8",
         "EUR_NOK",
         "CURRENCY",
         "EUR/NOK",
         "-4",
         "5",
         "0",
         "1",
         "1.00000",
         "0.00050"
        ],
        [
         "9",
         "USD_CAD",
         "CURRENCY",
         "USD/CAD",
         "-4",
         "5",
         "0",
         "1",
         "1.00000",
         "0.00050"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>displayName</th>\n",
       "      <th>pipLocation</th>\n",
       "      <th>displayPrecision</th>\n",
       "      <th>tradeUnitsPrecision</th>\n",
       "      <th>minimumTradeSize</th>\n",
       "      <th>maximumTrailingStopDistance</th>\n",
       "      <th>minimumTrailingStopDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRY_JPY</td>\n",
       "      <td>CURRENCY</td>\n",
       "      <td>TRY/JPY</td>\n",
       "      <td>-2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUD_JPY</td>\n",
       "      <td>CURRENCY</td>\n",
       "      <td>AUD/JPY</td>\n",
       "      <td>-2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USD_CNH</td>\n",
       "      <td>CURRENCY</td>\n",
       "      <td>USD/CNH</td>\n",
       "      <td>-4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NZD_JPY</td>\n",
       "      <td>CURRENCY</td>\n",
       "      <td>NZD/JPY</td>\n",
       "      <td>-2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUR_GBP</td>\n",
       "      <td>CURRENCY</td>\n",
       "      <td>EUR/GBP</td>\n",
       "      <td>-4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHF_HKD</td>\n",
       "      <td>CURRENCY</td>\n",
       "      <td>CHF/HKD</td>\n",
       "      <td>-4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>USD_CZK</td>\n",
       "      <td>CURRENCY</td>\n",
       "      <td>USD/CZK</td>\n",
       "      <td>-4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NZD_HKD</td>\n",
       "      <td>CURRENCY</td>\n",
       "      <td>NZD/HKD</td>\n",
       "      <td>-4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EUR_NOK</td>\n",
       "      <td>CURRENCY</td>\n",
       "      <td>EUR/NOK</td>\n",
       "      <td>-4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>USD_CAD</td>\n",
       "      <td>CURRENCY</td>\n",
       "      <td>USD/CAD</td>\n",
       "      <td>-4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name      type displayName  pipLocation  displayPrecision  \\\n",
       "0  TRY_JPY  CURRENCY     TRY/JPY           -2                 3   \n",
       "1  AUD_JPY  CURRENCY     AUD/JPY           -2                 3   \n",
       "2  USD_CNH  CURRENCY     USD/CNH           -4                 5   \n",
       "3  NZD_JPY  CURRENCY     NZD/JPY           -2                 3   \n",
       "4  EUR_GBP  CURRENCY     EUR/GBP           -4                 5   \n",
       "5  CHF_HKD  CURRENCY     CHF/HKD           -4                 5   \n",
       "6  USD_CZK  CURRENCY     USD/CZK           -4                 5   \n",
       "7  NZD_HKD  CURRENCY     NZD/HKD           -4                 5   \n",
       "8  EUR_NOK  CURRENCY     EUR/NOK           -4                 5   \n",
       "9  USD_CAD  CURRENCY     USD/CAD           -4                 5   \n",
       "\n",
       "   tradeUnitsPrecision minimumTradeSize maximumTrailingStopDistance  \\\n",
       "0                    0                1                     100.000   \n",
       "1                    0                1                     100.000   \n",
       "2                    0                1                     1.00000   \n",
       "3                    0                1                     100.000   \n",
       "4                    0                1                     1.00000   \n",
       "5                    0                1                     1.00000   \n",
       "6                    0                1                     1.00000   \n",
       "7                    0                1                     1.00000   \n",
       "8                    0                1                     1.00000   \n",
       "9                    0                1                     1.00000   \n",
       "\n",
       "  minimumTrailingStopDistance  \n",
       "0                       0.050  \n",
       "1                       0.050  \n",
       "2                     0.00050  \n",
       "3                       0.050  \n",
       "4                     0.00050  \n",
       "5                     0.00050  \n",
       "6                     0.00050  \n",
       "7                     0.00050  \n",
       "8                     0.00050  \n",
       "9                     0.00050  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instrument types available:\n",
      "type\n",
      "CURRENCY    68\n",
      "Name: count, dtype: int64\n",
      "\n",
      "All instrument names:\n",
      "['TRY_JPY', 'AUD_JPY', 'USD_CNH', 'NZD_JPY', 'EUR_GBP', 'CHF_HKD', 'USD_CZK', 'NZD_HKD', 'EUR_NOK', 'USD_CAD', 'EUR_AUD', 'EUR_SGD', 'USD_HKD', 'CAD_HKD', 'USD_CHF', 'AUD_HKD', 'NZD_CHF', 'AUD_CHF', 'GBP_CHF', 'USD_THB', 'EUR_HKD', 'CHF_JPY', 'GBP_HKD', 'EUR_NZD', 'AUD_SGD', 'EUR_JPY', 'EUR_TRY', 'USD_JPY', 'SGD_JPY', 'GBP_ZAR', 'ZAR_JPY', 'USD_SEK', 'GBP_SGD', 'CAD_CHF', 'AUD_NZD', 'HKD_JPY', 'USD_NOK', 'GBP_AUD', 'USD_PLN', 'EUR_ZAR', 'NZD_USD', 'USD_ZAR', 'CAD_JPY', 'CAD_SGD', 'USD_HUF', 'EUR_CAD', 'CHF_ZAR', 'USD_DKK', 'EUR_HUF', 'EUR_CHF', 'EUR_DKK', 'EUR_USD', 'EUR_CZK', 'NZD_CAD', 'SGD_CHF', 'GBP_JPY', 'USD_TRY', 'GBP_PLN', 'AUD_USD', 'GBP_USD', 'USD_MXN', 'GBP_CAD', 'AUD_CAD', 'EUR_PLN', 'GBP_NZD', 'EUR_SEK', 'USD_SGD', 'NZD_SGD']\n"
     ]
    }
   ],
   "source": [
    "# Get all available instruments\n",
    "instruments_df = list_instruments()\n",
    "\n",
    "if instruments_df is not None:\n",
    "    # Display first few instruments\n",
    "    print(\"\\nFirst 10 instruments:\")\n",
    "    display(instruments_df.head(10))\n",
    "    \n",
    "    # Display instrument types\n",
    "    print(\"\\nInstrument types available:\")\n",
    "    print(instruments_df['type'].value_counts())\n",
    "    \n",
    "    # Display all instrument names\n",
    "    print(\"\\nAll instrument names:\")\n",
    "    print(instruments_df['name'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8acb405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 11 parquet files for missing data...\n",
      "Missing data found in file EUR_CHF_2005_S5_BA.parquet: percentage of missing values: 22.47%\n",
      "No missing data in file EUR_CHF_2006_S5_BA.parquet.\n",
      "No missing data in file EUR_CHF_2007_S5_BA.parquet.\n",
      "Missing data found in file EUR_CHF_2008_S5_BA.parquet: percentage of missing values: 0.58%\n",
      "No missing data in file EUR_CHF_2009_S5_BA.parquet.\n",
      "No missing data in file EUR_CHF_2010_S5_BA.parquet.\n",
      "No missing data in file EUR_CHF_2011_S5_BA.parquet.\n",
      "No missing data in file EUR_CHF_2012_S5_BA.parquet.\n",
      "No missing data in file EUR_CHF_2013_S5_BA.parquet.\n",
      "No missing data in file EUR_CHF_2014_S5_BA.parquet.\n",
      "No missing data in file EUR_CHF_2015_S5_BA.parquet.\n"
     ]
    }
   ],
   "source": [
    "#Question: are there missing data points in the downloaded data?\n",
    "# Explanation: this cell had been used for 2005-2015 data, in yearly chunks.\n",
    "\n",
    "import pandas as pd\n",
    "# Let's check all the data we have for NaNs\n",
    "import os\n",
    "data_dir = 'data/raw'\n",
    "files = sorted([f for f in os.listdir(data_dir) if f.endswith('.parquet')])\n",
    "print(f\"Checking {len(files)} parquet files for missing data...\")\n",
    "for f in files:\n",
    "    df = pd.read_parquet(os.path.join(data_dir, f))\n",
    "    if df.isnull().values.any():\n",
    "        missing_percentage = df.isnull().mean().mean() * 100\n",
    "        print(f\"Missing data found in file {f}: percentage of missing values: {missing_percentage:.2f}%\")\n",
    "    else:\n",
    "        print(f\"No missing data in file {f}.\")\n",
    "\n",
    "# Conclusion: Missing data found in 2005 (22%) and 2008 (0.03%); other years are clean.\n",
    "# Decided: start analysis from 2009 onward (see features.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01486bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 7 parquet files for differences in 'a_t', 'b_t', 'm_t'...\n",
      "No differences in file EUR_CHF_2009_S5_BA.parquet.\n",
      "No differences in file EUR_CHF_2010_S5_BA.parquet.\n",
      "No differences in file EUR_CHF_2011_S5_BA.parquet.\n",
      "No differences in file EUR_CHF_2012_S5_BA.parquet.\n",
      "No differences in file EUR_CHF_2013_S5_BA.parquet.\n",
      "No differences in file EUR_CHF_2014_S5_BA.parquet.\n",
      "No differences in file EUR_CHF_2015_S5_BA.parquet.\n"
     ]
    }
   ],
   "source": [
    "# Question: do 'a_t, 'b_t', 'm_t' (number of quotes per candle) ever differ within the same candle?\n",
    "# Explanation: this cell had been used for data with 'a_t', 'b_t', 'm_t' columns.\n",
    "\n",
    "import pandas as pd\n",
    "# Let's check all the data we have for differences\n",
    "import os\n",
    "data_dir = 'data/raw'\n",
    "files = sorted([f for f in os.listdir(data_dir) if f.endswith('.parquet')])\n",
    "print(f\"Checking {len(files)} parquet files for differences in 'a_t', 'b_t', 'm_t'...\")\n",
    "for f in files:\n",
    "    df = pd.read_parquet(os.path.join(data_dir, f))\n",
    "    diffs = df[(df['a_t'] != df['b_t']) | (df['a_t'] != df['m_t']) | (df['b_t'] != df['m_t'])]\n",
    "    if not diffs.empty:\n",
    "        print(f\"Differences found in file {f} in {len(diffs)} candles:\")\n",
    "        print(diffs)   \n",
    "    else:   \n",
    "        print(f\"No differences in file {f}.\") \n",
    "\n",
    "# Conclusion: No differences found in any year. All 'a_t', 'b_t', 'm_t' are identical per candle. Let's keep 'm_t'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e709ebd",
   "metadata": {},
   "source": [
    "Test the algorithm for time-since-last-true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e054c41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a  since_a\n",
      "0   1      NaN\n",
      "1   0      1.0\n",
      "2   0      2.0\n",
      "3   0      3.0\n",
      "4   1      4.0\n",
      "5   0      1.0\n",
      "6   1      2.0\n",
      "7   0      1.0\n",
      "8   1      2.0\n",
      "9   1      1.0\n",
      "10  1      1.0\n",
      "11  0      1.0\n",
      "12  0      2.0\n",
      "13  1      3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create an artificial DataFrame for testing\n",
    "df = pd.DataFrame({\n",
    "    'a': [1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1],\n",
    "    # 'b': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "})\n",
    "\n",
    "\n",
    "def since_last_nonzero_nonshifted(series):\n",
    "    mask = series != 0\n",
    "    # cumsum increases at each nonzero, so group by this\n",
    "    group = mask.cumsum()\n",
    "    # Where group==0, it's before the first nonzero, so set to nan\n",
    "    result = series.groupby(group).cumcount() + 1\n",
    "    result[group == 0] = np.nan\n",
    "    return result.values\n",
    "\n",
    "def add_since_last_nonzero(df, col, new_col):\n",
    "    df[new_col] = since_last_nonzero_nonshifted(df[col])\n",
    "    df[new_col] = df[new_col].shift()\n",
    "    return df\n",
    "\n",
    "df = add_since_last_nonzero(df, 'a', 'since_a')\n",
    "# df = add_since_last_nonzero(df, 'b', 'since_b')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11045d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     x  x_future\n",
      "2024-01-01 00:00:00  0       3.0\n",
      "2024-01-01 00:01:00  1       4.0\n",
      "2024-01-01 00:02:00  2       5.0\n",
      "2024-01-01 00:03:00  3       6.0\n",
      "2024-01-01 00:04:00  4       7.0\n",
      "2024-01-01 00:05:00  5       8.0\n",
      "2024-01-01 00:06:00  6       9.0\n"
     ]
    }
   ],
   "source": [
    "# Testing the future-shifted feature function\n",
    "\n",
    "import pandas as pd\n",
    "rng = pd.date_range('2024-01-01', periods=10, freq='1min')\n",
    "df = pd.DataFrame({'x': range(10)}, index=rng)\n",
    "%run ../scripts/build_features.py\n",
    "df = add_future_shifted_feature(df, 'x', 'x_future', freq='3min')\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
